{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "L101 preprocess sentence selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAlkemade/bert-for-fever/blob/master/L101_preprocess_sentence_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_jWDYDSad1x",
        "colab_type": "text"
      },
      "source": [
        "# Preprocess the data\n",
        "The end result is a .tsv file with the columns:\n",
        "\n",
        "\n",
        "*   id\n",
        "*   label (evidence or not)\n",
        "*   sentence (from wikipedia)\n",
        "*   claim\n",
        "\n",
        "```bash\n",
        "jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L313qoQ77uOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST = False\n",
        "EMPTY_TOKEN = 'EMPTY'\n",
        "OUT_FILE_NAME = 'dev_sentences_from_bert_doc_selector'\n",
        "GOLD = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lypDYTz8bjRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import json\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "db = 'D:/GitHubD/fever-allennlp/data/fever/fever.db'\n",
        "# in_file_fname = 'D:/GitHubD/fever-allennlp/data/dev_complete.sentences.p5.s5.jsonl'\n",
        "in_file_fname = 'D:/GitHubD/fever-allennlp/data/fever-data/predictions_doc_dev_bert.jsonl'\n",
        "out_file = f'D:/GitHubD/L101/data/{OUT_FILE_NAME}.tsv'\n",
        "\n",
        "conn = sqlite3.connect(db)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PCW5tk9dcrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VWDypjmgv6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_doc_text(id):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\n",
        "        \"SELECT lines FROM documents WHERE id = ?\",\n",
        "        (id,)\n",
        "    )\n",
        "    result = cursor.fetchone()\n",
        "    cursor.close()\n",
        "    return result\n",
        "\n",
        "def get_golden_docs_sentences(evidence):\n",
        "    all_evi = [[e[2], e[3]] for eg in instance[\"evidence\"] for e in eg if e[3] is not None] # from baseline scorer\n",
        "    gold_docs_sentences = {}\n",
        "    for entry in all_evi:\n",
        "        id = entry[0]\n",
        "        sentence_idx = entry[1]\n",
        "        gold_docs_sentences.setdefault(id, []).append(sentence_idx)\n",
        "        \n",
        "    return gold_docs_sentences\n",
        "\n",
        "def parse_doc(doc_raw):\n",
        "    \"\"\"\n",
        "    Parse a list of lines from a raw document text, with the index in the list\n",
        "    correponding to the line index in the data entries\n",
        "    \"\"\"\n",
        "    new = []\n",
        "    lines = doc_raw.split(\"\\n\")\n",
        "    char_count = 0\n",
        "    for line in lines:\n",
        "        # print('Line: {}'.format(line))\n",
        "        line = line.split(\"\\t\")\n",
        "        \n",
        "    #   TODO: THIS MIGHT DROP PARTS OF SENTENCES AFTER A TAB\n",
        "        if len(line[1]) > 1:\n",
        "            new.append(line[1])\n",
        "            char_count += len(line[1])\n",
        "        else:\n",
        "            new.append(EMPTY_TOKEN)\n",
        "    chars.append(char_count)\n",
        "    return new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T96z7W1KbbMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: WAT DOEN WE MET DE NOT VERIFIABLES?\n",
        "claim_lengths = []\n",
        "with open(in_file_fname, \"r\") as in_file:\n",
        "    instances = []\n",
        "    for line in in_file:\n",
        "        instances.append(json.loads(line))\n",
        "    print(f\"Number of instances: {len(instances)}\")\n",
        "   \n",
        "    training_instances = []\n",
        "    if TEST:\n",
        "        new_instances = []\n",
        "        for instance in instances:\n",
        "            if instance['id'] == 137334:\n",
        "                new_instances.append(instance)\n",
        "        instances= new_instances\n",
        "    for step, instance in enumerate(instances):\n",
        "        if step % 1000 == 0:\n",
        "            print(f'At step {step}')\n",
        "        if instance['verifiable'] != 'NOT VERIFIABLE':\n",
        "            claim = instance['claim']\n",
        "            claim_lengths.append(len(claim))\n",
        "            claim_id = instance['id']\n",
        "            gold_docs_sentences = get_golden_docs_sentences(instance['evidence'])\n",
        "            if not GOLD:\n",
        "                docs = instance['predicted_pages']\n",
        "            else:\n",
        "                docs = gold_docs_sentences.keys()\n",
        "            \n",
        "            for doc_id in docs:\n",
        "                doc_sentences = parse_doc(get_doc_text(doc_id)[0])\n",
        "                if doc_id in gold_docs_sentences.keys():\n",
        "                    gold_sentences_idx = gold_docs_sentences[doc_id]\n",
        "                else:\n",
        "                    gold_sentences_idx = []\n",
        "                    \n",
        "                for i in range(len(doc_sentences)):\n",
        "                    if i in gold_sentences_idx:\n",
        "                        label = 1\n",
        "                    else:\n",
        "                        label = 0\n",
        "                    sentence = doc_sentences[i]\n",
        "                    if sentence != EMPTY_TOKEN:\n",
        "                        training_instances.append([label, claim, sentence, claim_id, doc_id, i])\n",
        "            # print(instance['evidence'])\n",
        "            # print(instance['evidence'][0])\n",
        "            # print(gold_docs_sentences)\n",
        "    \n",
        "    data = pd.DataFrame(training_instances, columns =['evidence', 'claim', 'sentence', 'id', 'doc_id', 'sentence_idx']) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQX2WqYay6Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_csv(out_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctj2S_VeduD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.mean(chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL5ARxZklyMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(chars)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PXuvjBg3chn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.mean(claim_lengths))\n",
        "plt.hist(claim_lengths, bins=30)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InjhhkA5Ug2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(data.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Or_FvW8wQv",
        "colab_type": "text"
      },
      "source": [
        "        # TODO: think about what to take as negative samples; just save all for now\n",
        "        #  But the BERT article does HNM (Hard negative Mining);\n",
        "        # look into that\n",
        "\n",
        "        #Do:\n",
        "        # get all sentences that are in the training instance. Loop over and label them using the instance data\n",
        "        # add every sentence as a line to a pandas dataframe\n",
        "        # save it as a .tsv"
      ]
    }
  ]
}