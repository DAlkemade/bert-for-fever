{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DAlkemade/bert-for-fever/blob/master/L101_tokenize_for_document_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yP8FttSN5EPb",
    "colab_type": "text"
   },
   "source": [
    "Tokenize the data in a .tsv file of features to use as input for a BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "HJjjbEf-2tMd",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "p8WRYYbj14bE",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "import torch\n",
    "from transformers import *\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset, WeightedRandomSampler)\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "7YWkleQ01ZR-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "TEST = False\n",
    "MAX_SENTENCE_LENGTH = 512 #maybe make smaller and then batch size higher\n",
    "PADDING_TOKEN_TYPE_ID = 0 # take the advice at https://github.com/huggingface/transformers/blob/0cb163865a4c761c226b151283309eedb2b1ca4d/transformers/data/processors/glue.py#L30\n",
    "WORK_DIR = '/content/drive/My Drive/Overig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "aaeKUeh35SXA",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "data_fname = '/content/drive/My Drive/Overig/document_selection_test_n=50.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uuha10L2CHCC",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "pS35k9Jn1zVw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_fname)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "U_UsPD5Zb6qB",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    data= data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "isjTxH0W17pa",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print(f\"Number of training instances: {len(data.index)}\")\n",
    "print(f'Number of claims in training set: {len(list(dict.fromkeys(data.claim_id)))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "NxmYz4t96nxw",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "pad_token = tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "8CeQBeC1ipxh",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def prep_instance(claim, context, label, doc_id):\n",
    "    \n",
    "    # print(f'Total length: {len(claim) + len(source_sentence)}')\n",
    "    context = f'[ {doc_id} ] {context}'\n",
    "    encodings = tokenizer.encode_plus(claim, context, add_special_tokens=True, max_length=MAX_SENTENCE_LENGTH) # I expect this will cut off the documents\n",
    "    input_ids, token_type_ids = encodings[\"input_ids\"], encodings[\"token_type_ids\"]\n",
    "    # We mask padding with 0\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    # Pad on the right\n",
    "    padding_length = MAX_SENTENCE_LENGTH - len(input_ids)\n",
    "    # The next 3 lines are taken from the example at https://github.com/huggingface/transformers/blob/0cb163865a4c761c226b151283309eedb2b1ca4d/transformers/data/processors/glue.py#L30\n",
    "    input_ids = input_ids + ([pad_token] * padding_length)\n",
    "    # We mask padding with 0\n",
    "    attention_mask = attention_mask + ([0] * padding_length)\n",
    "    token_type_ids = token_type_ids + ([PADDING_TOKEN_TYPE_ID] * padding_length)\n",
    "    return InputFeatures(input_ids=input_ids,attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids, label=label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YTRFKwrqPjFi",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def create_features(data, dev=False):\n",
    "    claims = list(data.claim)\n",
    "    contexts = list(data.context)\n",
    "    labels = list(data.label)\n",
    "    claim_ids = list(data.claim_id)\n",
    "    doc_ids = list(data.doc_id)\n",
    "    features = [prep_instance(claims[i], contexts[i], labels[i], doc_ids[i]) for i in tqdm(range(len(claims)))]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "UZi6W7v47ORc",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# print(\"Create features\")\n",
    "features = create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "KgJjMWSxm9f0",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "print(\"Save features\")\n",
    "torch.save(features, os.path.join(WORK_DIR, f'{datetime.now().strftime(\"%y%m%d%H%M%S\")}features_document_selection_from_{data_fname.split(\".\")[0].split(\"/\")[-1]}'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "L101 tokenize for document selection",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
